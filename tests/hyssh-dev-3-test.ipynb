{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Testing with SDK v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import logging\n",
    "\n",
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Enter details of your AML workspace\n",
    "subscription_id = \"89da9f33-fd31-4ece-861e-5fab7af4dc11\"\n",
    "resource_group = \"mtcs-dev-aml-rg\"\n",
    "workspace = \"mtcs-dev-aml\"\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "from src.ray_on_aml.core import Ray_On_AML\n",
    "\n",
    "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"ray-on-aml-workers\")\n",
    "\n",
    "ray = ray_on_aml.getRay(num_node=2, pip_packages=[\"fastparquet==2022.12.0\", \"azureml-mlflow==1.48.0\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs==2022.11.2\", \"fsspec==2022.11.0\", \"tqdm\"])\n",
    "client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.available_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ray also support Ray dataset. You can read into ray dataset then convert to Dask or other ML format which is convenient for ML training.https://docs.ray.io/en/latest/data/dataset.html\n",
    "# you may need to upgrade pyarrow to run this successfully\n",
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "abfs = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
    "#if read all years and months\n",
    "# data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather//\", filesystem=abfs)\n",
    "data =ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2015/\"], filesystem=abfs)\n",
    "# data.count()\n",
    "# 1,584,481,119 is the count for all data \n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray_on_aml.shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice:\n",
      "maxnode will be deprecated in the future. It will be moved to num_node in getRay() method.\n",
      "ray[default]==2.0.0 is found in your environment.\n",
      "Ray 2.0.0 version will be install in your compute cluster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'ray-on-aml-3681562929' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'ray-on-aml-3681562929' will not be used for anonymous registration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting cluster to start and return head node's ip\n",
      ".......\n",
      " cluster is ready, head node ip  10.0.0.6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import logging\n",
    "\n",
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Enter details of your AML workspace\n",
    "subscription_id = \"89da9f33-fd31-4ece-861e-5fab7af4dc11\"\n",
    "resource_group = \"mtcs-dev-aml-rg\"\n",
    "workspace = \"mtcs-dev-aml\"\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "from src.ray_on_aml.core import Ray_On_AML\n",
    "\n",
    "from azure.ai.ml import command, Input, Output\n",
    "import logging\n",
    "\n",
    "\n",
    "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"ray-on-aml-workers\")\n",
    "\n",
    "\n",
    "inputs={\n",
    "        \"diabetes\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"azureml://datastores/workspaceblobstore/paths/data03022022\",\n",
    "        )\n",
    "    }\n",
    "\n",
    "outputs={\n",
    "    \"output1\": Output(\n",
    "        type=\"uri_folder\",\n",
    "        path=\"azureml://datastores/workspaceblobstore/paths/ray_outputs\",\n",
    "    )\n",
    "}\n",
    "\n",
    "ray = ray_on_aml.getRay(inputs = inputs, outputs=outputs, num_node=2, \n",
    "                        pip_packages=[\"fastparquet==2022.12.0\", \"azureml-mlflow==1.48.0\", \n",
    "                                    \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs==2022.11.2\", \n",
    "                                    \"fsspec==2022.11.0\", \"tqdm\"])\n",
    "\n",
    "client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ray.data.range(100) \n",
    "ds.write_csv(ray_on_aml.mount_points['output1']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ray.data.read_csv(ray_on_aml.mount_points['output1']) \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 02:04:20,828\tWARNING read_api.py:291 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n",
      "Read: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.05it/s]\n",
      "Repartition: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  6.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.8)\u001b[0m /azureml-envs/azureml_c9f02056f99271e9bd887c91b48da60e/lib/python3.10/site-packages/ray/dashboard/agent.py:50: DeprecationWarning: There is no current event loop\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.8)\u001b[0m   aiogrpc.init_grpc_aio()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.8)\u001b[0m /azureml-envs/azureml_c9f02056f99271e9bd887c91b48da60e/lib/python3.10/site-packages/ray/dashboard/agent.py:470: DeprecationWarning: There is no current event loop\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.8)\u001b[0m   loop = asyncio.get_event_loop()\n"
     ]
    }
   ],
   "source": [
    "fileName = ray_on_aml.mount_points['diabetes']\n",
    "# fileName = ray_on_aml.mount_points['batch_data']\n",
    "# fileName =\"/mnt/batch/tasks/shared/LS_root/jobs/mtcs-dev-aml/azureml/happy_brain_j2376wy44j/wd/greenTaxi_uri/unprepared.parquet\"\n",
    "# fileName = \"/mnt/batch/tasks/shared/LS_root/jobs/mtcs-dev-aml/azureml/eager_school_mnkf627spt/wd/diabetes_uri\"\n",
    "\n",
    "data = ray.data.read_csv(fileName).repartition(4)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.00</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.00</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.00</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.00</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.00</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>112.00</td>\n",
       "      <td>185</td>\n",
       "      <td>113.8</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.9836</td>\n",
       "      <td>93</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>24.9</td>\n",
       "      <td>75.00</td>\n",
       "      <td>225</td>\n",
       "      <td>166.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.4427</td>\n",
       "      <td>102</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>24.9</td>\n",
       "      <td>99.67</td>\n",
       "      <td>162</td>\n",
       "      <td>106.6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>4.1271</td>\n",
       "      <td>95</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>95.00</td>\n",
       "      <td>201</td>\n",
       "      <td>125.2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>5.1299</td>\n",
       "      <td>85</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>19.6</td>\n",
       "      <td>71.00</td>\n",
       "      <td>250</td>\n",
       "      <td>133.2</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5951</td>\n",
       "      <td>92</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX   BMI      BP   S1     S2    S3    S4      S5   S6    Y\n",
       "0     59    2  32.1  101.00  157   93.2  38.0  4.00  4.8598   87  151\n",
       "1     48    1  21.6   87.00  183  103.2  70.0  3.00  3.8918   69   75\n",
       "2     72    2  30.5   93.00  156   93.6  41.0  4.00  4.6728   85  141\n",
       "3     24    1  25.3   84.00  198  131.4  40.0  5.00  4.8903   89  206\n",
       "4     50    1  23.0  101.00  192  125.4  52.0  4.00  4.2905   80  135\n",
       "..   ...  ...   ...     ...  ...    ...   ...   ...     ...  ...  ...\n",
       "437   60    2  28.2  112.00  185  113.8  42.0  4.00  4.9836   93  178\n",
       "438   47    2  24.9   75.00  225  166.0  42.0  5.00  4.4427  102  104\n",
       "439   60    2  24.9   99.67  162  106.6  43.0  3.77  4.1271   95  132\n",
       "440   36    1  30.0   95.00  201  125.2  42.0  4.79  5.1299   85  220\n",
       "441   36    1  19.6   71.00  250  133.2  97.0  3.00  4.5951   92   57\n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object_store_memory': 4118717644.0,\n",
       " 'node:10.0.0.6': 1.0,\n",
       " 'memory': 8237435291.0,\n",
       " 'CPU': 4.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n",
    "ray_on_aml.shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adlfs import AzureBlobFileSystem\n",
    "#install dask, adlfs \n",
    "import dask.dataframe as dd\n",
    "from ray.util.dask import ray_dask_get, enable_dask_on_ray, disable_dask_on_ray\n",
    "enable_dask_on_ray()\n",
    "abfs = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
    "\n",
    "storage_options = {'account_name': 'azureopendatastorage'}\n",
    "ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
    "\n",
    "# data = ray.data.read_parquet(ray_on_aml.mount_points['ISDWeather'])\n",
    "\n",
    "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs)\n",
    "print(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Testing with SDK v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "import importlib\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ray_on_aml.core import Ray_On_AML\n",
    "\n",
    "\n",
    "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"ray-on-aml-workers\", maxnode=2)\n",
    "ray = ray_on_aml.getRay(ci_is_head =True, num_node=2,pip_packages=[\"torch==1.13.0\",\"fastparquet==2022.12.0\", \"azureml-mlflow==1.48.0\", \"pyarrow==6.0.1\", \"dask==2022.12.0\", \"adlfs==2022.11.2\", \"fsspec==2022.11.0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "# Load data.\n",
    "dataset = ray.data.read_csv(\"s3://anonymous@air-example-data/breast_cancer.csv\")\n",
    "\n",
    "# Split data into train and validation.\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# Create a test dataset by dropping the target column.\n",
    "test_dataset = valid_dataset.drop_columns(cols=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
    "\n",
    "from ray import train\n",
    "from ray.air import session\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
    "\n",
    "\n",
    "def create_model(input_features):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features=input_features, out_features=16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 1),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"num_epochs\"]\n",
    "    num_features = config[\"num_features\"]\n",
    "\n",
    "    # Get the Ray Dataset shard for this data parallel worker,\n",
    "    # and convert it to a PyTorch Dataset.\n",
    "    train_data = train.get_dataset_shard(\"train\")\n",
    "    # Create model.\n",
    "    model = create_model(num_features)\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for cur_epoch in range(epochs):\n",
    "        for batch in train_data.iter_torch_batches(\n",
    "            batch_size=batch_size, dtypes=torch.float32\n",
    "        ):\n",
    "            # \"concat_out\" is the output column of the Concatenator.\n",
    "            inputs, labels = batch[\"concat_out\"], batch[\"target\"]\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(inputs)\n",
    "            train_loss = loss_fn(predictions, labels.unsqueeze(1))\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        loss = train_loss.item()\n",
    "        session.report({\"loss\": loss}, checkpoint=TorchCheckpoint.from_model(model))\n",
    "\n",
    "\n",
    "num_features = len(train_dataset.schema().names) - 1\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\n",
    "        \"batch_size\": 128,\n",
    "        \"num_epochs\": 20,\n",
    "        \"num_features\": num_features,\n",
    "        \"lr\": 0.001,\n",
    "    },\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=2,  # Number of workers to use for data parallelism.\n",
    "        use_gpu=False,\n",
    "        trainer_resources={\"CPU\": 1},  # so that the example works on Colab.\n",
    "    ),\n",
    "    datasets={\"train\": train_dataset},\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "# Execute training.\n",
    "result = trainer.fit()\n",
    "print(f\"Last result: {result.metrics}\")\n",
    "# Last result: {'loss': 0.6559339960416158, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_on_aml.shutdown(True)\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
